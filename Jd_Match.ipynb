{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KUBERNETES_SERVICE_PORT_HTTPS=\n",
      "NODE_MAX_SPACE_SIZE=4096\n",
      "KUBERNETES_SERVICE_PORT=\n",
      "USER_NAME=srrs@deloitte.com\n",
      "HOME=/home/user\n",
      "KUBERNETES_PORT_443_TCP=\n",
      "TENANT_PLAN=standard-edition\n",
      "BAS_DEFAULT_PYTHON_VERSION=3.11.2\n",
      "DESTINATION_PROXY_URL=http://secure-outbound-connectivity.webide-system\n",
      "SWA_FIELD_MAPPING=\n",
      "ASDF_DATA_DIR=/home/user/.asdf-inst\n",
      "https_proxy=http://127.0.0.1:8887\n",
      "OUTPUT_CHANNEL_TRACE_LOCATION=/extbin/generators/simple-extension-yo-install-output.txt\n",
      "SWA_TARGET_SITE_URL=https://webanalytics2.cfapps.eu10.hana.ondemand.com/tracker/log\n",
      "TENANT_SUBDOMAIN=coe-asset-b9jxgzf0\n",
      "SWA_MINIMAL_ALLOWED_VERSION=1.2.11\n",
      "KMP_INIT_AT_FORK=FALSE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma DB loaded from existing directory.\n",
      "Welcome to Job Profile Matcher\n",
      "Job Descriptions Loaded:\n",
      "               Title                                Description  \\\n",
      "0  Software Engineer  Develop and maintain software application   \n",
      "1     Data Scientist    Analyze data and build predictive model   \n",
      "2    Project Manager                  Oversee project timelines   \n",
      "\n",
      "             Skills   Location Experience   Salary  \n",
      "0       Java,Python  Bengaluru   3-5Years  8000000  \n",
      "1         Python,ML      Delhi   3-5Years   900000  \n",
      "2  Agile,Leadership    Germany   4-5years  1000000  \n",
      "Job Descriptions are already stored in Chroma DB.\n",
      "Enter the profile links (up to 4). Leave blank to stop.\n",
      "Error: LLM response is not valid JSON. Please check the response format.\n",
      "LLM Response: The provided text does not contain any specific job postings with details such as Title, Description, Skills, Location, Experience, or Salary. It appears to be a mix of website navigation instructions, user interface messages, and general information about a tech community platform. Therefore, there are no job postings to extract and format into JSON. If you have another text or specific job postings, please provide them, and I can assist you further.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "Exiting program due to invalid LLM response.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Exiting program due to invalid LLM response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/projects/JD/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from appconfig import AppConfig\n",
    "from azureai import AzureAI\n",
    "\n",
    "# Create instances of AppConfig and AzureAI\n",
    "config = AppConfig()\n",
    "azure_ai = AzureAI(config)\n",
    "\n",
    "import sys  # Import sys to enable program termination\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "# Initialize the LLM client\n",
    "llm = azure_ai.get_client()\n",
    "\n",
    "# Function to preprocess and combine JD fields\n",
    "def preprocess_jd(row):\n",
    "    combined_text = f\"\"\"\n",
    "    Title: {row.get('Title', 'N/A')}\n",
    "    Description: {row.get('Description', 'N/A')}\n",
    "    Skills: {row.get('Skills', 'N/A')}\n",
    "    Location: {row.get('Location', 'N/A')}\n",
    "    Experience: {row.get('Experience', 'N/A')}\n",
    "    Salary: {row.get('Salary', 'N/A')}\n",
    "    \"\"\"\n",
    "    return combined_text.strip()\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# File and Chroma DB setup\n",
    "chroma_db_name = \"jd_chroma_db\"\n",
    "chroma_persist_dir = \"chroma_db\"\n",
    "\n",
    "# Load or initialize Chroma DB\n",
    "if os.path.exists(chroma_persist_dir) and os.listdir(chroma_persist_dir):\n",
    "    chroma_db = Chroma(collection_name=chroma_db_name, embedding_function=embeddings, persist_directory=chroma_persist_dir)\n",
    "    print(\"Chroma DB loaded from existing directory.\")\n",
    "else:\n",
    "    chroma_db = Chroma(collection_name=chroma_db_name, embedding_function=embeddings, persist_directory=chroma_persist_dir)\n",
    "    print(\"New Chroma DB initialized.\")\n",
    "\n",
    "def extract_profile_details(profile_text):\n",
    "    # Define the LLM and prompt for profile extraction\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"profile_text\"],\n",
    "        template=\"\"\"\n",
    "        The scraped text is from the career's page of a website.\n",
    "        Your job is to extract the job postings and return them in JSON format containing the\n",
    "        following keys:\n",
    "        Title, Description, Skills, Location, Experience, Salary.\n",
    "        Profile Text:\n",
    "        {profile_text}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    response = chain.run(profile_text)\n",
    "\n",
    "    try:\n",
    "        # Safely parse the JSON response\n",
    "        profile_details = json.loads(response)\n",
    "        return profile_details\n",
    "    except json.JSONDecodeError:\n",
    "        # Handle invalid JSON response\n",
    "        print(\"Error: LLM response is not valid JSON. Please check the response format.\")\n",
    "        print(f\"LLM Response: {response}\")\n",
    "        sys.exit(\"Exiting program due to invalid LLM response.\")\n",
    "\n",
    "def main():\n",
    "    print(\"Welcome to Job Profile Matcher\")\n",
    "\n",
    "    # Step 1: Upload CSV file\n",
    "    jd_file_path = input(\"Enter the path to the JD CSV file: \").strip()\n",
    "\n",
    "    if not os.path.exists(jd_file_path):\n",
    "        print(\"File not found. Please check the path and try again.\")\n",
    "        return\n",
    "\n",
    "    # Load JD file\n",
    "    jd_df = pd.read_csv(jd_file_path)\n",
    "    print(\"Job Descriptions Loaded:\")\n",
    "    print(jd_df.head())\n",
    "\n",
    "    # Combine JD columns for vectorization\n",
    "    jd_df[\"Combined\"] = jd_df.apply(preprocess_jd, axis=1)\n",
    "\n",
    "    # Step 2: Store JDs in Chroma DB\n",
    "    if not os.path.exists(chroma_persist_dir) or not os.listdir(chroma_persist_dir):\n",
    "        store_jds = input(\"Do you want to store these JDs in the vector database? (yes/no): \").strip().lower()\n",
    "        if store_jds == \"yes\":\n",
    "            for _, row in jd_df.iterrows():\n",
    "                jd_text = row[\"Combined\"]\n",
    "                chroma_db.add_texts([jd_text], metadatas={\"Title\": row[\"Title\"]})\n",
    "\n",
    "            # Persist the database\n",
    "            chroma_db.persist()\n",
    "            print(\"Job Descriptions stored in Chroma DB!\")\n",
    "    else:\n",
    "        print(\"Job Descriptions are already stored in Chroma DB.\")\n",
    "\n",
    "    # Step 3: Input profile links\n",
    "    print(\"Enter the profile links (up to 4). Leave blank to stop.\")\n",
    "    profile_links = []\n",
    "    for i in range(4):\n",
    "        link = input(f\"Profile Link {i + 1}: \").strip()\n",
    "        if link:\n",
    "            profile_links.append(link)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    if not profile_links:\n",
    "        print(\"No profiles entered. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Step 4: Extract details and store profiles in Chroma DB\n",
    "    for link in profile_links:\n",
    "        try:\n",
    "            # Use UnstructuredURLLoader to extract data from the URL\n",
    "            loader = UnstructuredURLLoader(urls=[link])\n",
    "            documents = loader.load()\n",
    "            profile_text = \" \".join(doc.page_content for doc in documents)\n",
    "\n",
    "            # Extract details using LLM\n",
    "            profile_details = extract_profile_details(profile_text)\n",
    "            if profile_details is None:\n",
    "                continue  # Skip storing if extraction failed\n",
    "\n",
    "            # Combine extracted details into a single text block\n",
    "            combined_profile_text = preprocess_jd(pd.Series(profile_details))\n",
    "\n",
    "            # Store in Chroma DB\n",
    "            chroma_db.add_texts([combined_profile_text], metadatas=profile_details)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing URL {link}: {e}\")\n",
    "            sys.exit(\"Exiting program due to error while processing profiles.\")\n",
    "\n",
    "    chroma_db.persist()\n",
    "    print(\"Profiles stored in Chroma DB!\")\n",
    "\n",
    "    # Step 5: Match profiles with JDs\n",
    "    match_profiles = input(\"Do you want to match profiles with the stored JDs? (yes/no): \").strip().lower()\n",
    "    if match_profiles == \"yes\":\n",
    "        matching_results = []\n",
    "        for _, row in jd_df.iterrows():\n",
    "            jd_text = row[\"Combined\"]\n",
    "            matches = chroma_db.similarity_search(jd_text, top_k=3)  # Adjust top_k as needed\n",
    "            for match in matches:\n",
    "                match_percent = match[\"score\"] * 100  # Normalize score to percentage\n",
    "                matching_results.append((jd_text, match[\"metadata\"].get(\"Title\", \"Unknown\"), match_percent))\n",
    "\n",
    "        # Display results\n",
    "        for jd_text, title, percent in matching_results:\n",
    "            print(f\"JD: {jd_text}\")\n",
    "            print(f\"Matched Profile Title: {title}\")\n",
    "            print(f\"Matching Percentage: {percent:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
